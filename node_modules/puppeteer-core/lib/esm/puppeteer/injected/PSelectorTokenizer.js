/**
 * Copyright (c) 2020 Lea Verou
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
import { assert } from '../util/assert.js';
const TOKENS = {
    ["attribute" /* TokenType.Attribute */]: /\[\s*(?:(?<namespace>(?:\\.|[-\w\P{ASCII}])+|\*)?\|)?(?<name>(?:\\.|[-\w\P{ASCII}])+)\s*(?:(?<operator>\W?=)\s*(?<value>.+?)\s*(\s(?<caseSensitive>[iIsS]))?\s*)?\]/gu,
    ["id" /* TokenType.Id */]: /#(?<name>(?:\\.|[-\w\P{ASCII}])+)/gu,
    ["class" /* TokenType.Class */]: /\.(?<name>(?:\\.|[-\w\P{ASCII}])+)/gu,
    ["comma" /* TokenType.Comma */]: /\s*,\s*/g,
    ["combinator" /* TokenType.Combinator */]: /\s*(?:>{3,4}|[\s>+~])\s*/g,
    ["pseudo-element" /* TokenType.PseudoElement */]: /::(?<name>(?:\\.|[-\w\P{ASCII}])+)(?:\((?<argument>¶+)\))?/gu,
    ["pseudo-class" /* TokenType.PseudoClass */]: /:(?<name>(?:\\.|[-\w\P{ASCII}])+)(?:\((?<argument>¶+)\))?/gu,
    ["universal" /* TokenType.Universal */]: /(?:(?<namespace>\*|(?:\\.|[-\w\P{ASCII}])*)\|)?\*/gu,
    ["type" /* TokenType.Type */]: /(?:(?<namespace>\*|(?:\\.|[-\w\P{ASCII}])*)\|)?(?<name>(?:\\.|[-\w\P{ASCII}])+)/gu,
};
const getArgumentPatternByType = (type) => {
    switch (type) {
        case "pseudo-element" /* TokenType.PseudoElement */:
        case "pseudo-class" /* TokenType.PseudoClass */:
            return new RegExp(TOKENS[type].source.replace('(?<argument>¶+)', '(?<argument>.+)'), 'gu');
        default:
            return TOKENS[type];
    }
};
function assertTokenArray(tokens) {
    let offset = 0;
    for (const token of tokens) {
        switch (typeof token) {
            case 'string':
                throw new Error(`Unexpected sequence ${token} found at index ${offset}`);
            case 'object':
                offset += token.content.length;
                token.pos = [offset - token.content.length, offset];
                switch (token.type) {
                    case "combinator" /* TokenType.Combinator */:
                    case "comma" /* TokenType.Comma */:
                        token.content = token.content.trim() || ' ';
                        break;
                }
                break;
        }
    }
}
export function tokenize(selector, grammar = TOKENS) {
    if (!selector) {
        return [];
    }
    selector = selector.trim();
    const replacements = [];
    // Replace strings with placeholder
    {
        const state = { escaped: false, offset: 0 };
        for (let i = 0; i < selector.length; ++i) {
            if (state.escaped) {
                continue;
            }
            switch (selector[i]) {
                case '\\':
                    state.escaped = true;
                    break;
                case '"':
                case "'": {
                    if (!state.quoted) {
                        state.quoted = selector[i];
                        state.offset = i;
                        continue;
                    }
                    const quote = state.quoted;
                    if (quote !== selector[i]) {
                        continue;
                    }
                    delete state.quoted;
                    const offset = state.offset;
                    const value = selector.slice(state.offset, i + 1);
                    replacements.push({ value, offset });
                    const replacement = `${quote}${'§'.repeat(value.length - 2)}${quote}`;
                    selector =
                        selector.slice(0, offset) +
                            replacement +
                            selector.slice(offset + value.length);
                    break;
                }
            }
        }
    }
    // Replace parentheses with placeholder
    {
        const state = { escaped: false, nesting: 0, offset: 0 };
        for (let i = 0; i < selector.length; ++i) {
            if (state.escaped) {
                continue;
            }
            switch (selector[i]) {
                case '\\':
                    state.escaped = true;
                    break;
                case '(':
                    if (++state.nesting !== 1) {
                        continue;
                    }
                    state.offset = i;
                    break;
                case ')': {
                    if (--state.nesting !== 0) {
                        continue;
                    }
                    const { offset } = state;
                    const value = selector.slice(offset, i + 1);
                    replacements.push({ value, offset });
                    const replacement = `(${'¶'.repeat(value.length - 2)})`;
                    selector =
                        selector.slice(0, offset) +
                            replacement +
                            selector.slice(offset + value.length);
                    break;
                }
            }
        }
    }
    // Our goal here is basically try each token type on the selector, keeping
    // track of order. Hopefully by the end, we have an array of tokens.
    const tokens = [selector];
    for (const [type, pattern] of Object.entries(grammar)) {
        for (let i = 0; i < tokens.length; i++) {
            const token = tokens[i];
            if (typeof token !== 'string') {
                continue;
            }
            pattern.lastIndex = 0;
            const match = pattern.exec(token);
            if (!match) {
                continue;
            }
            const from = match.index - 1;
            const args = [];
            const content = match[0];
            const before = token.slice(0, from + 1);
            if (before) {
                args.push(before);
            }
            args.push({
                ...match.groups,
                type,
                content,
            });
            const after = token.slice(from + content.length + 1);
            if (after) {
                args.push(after);
            }
            tokens.splice(i, 1, ...args);
        }
    }
    assertTokenArray(tokens);
    // Replace placeholders in reverse order.
    for (const replacement of replacements.reverse()) {
        for (const token of tokens) {
            const { offset, value } = replacement;
            if (!(token.pos[0] <= offset && offset + value.length <= token.pos[1])) {
                continue;
            }
            const { content } = token;
            const tokenOffset = offset - token.pos[0];
            token.content =
                content.slice(0, tokenOffset) +
                    value +
                    content.slice(tokenOffset + value.length);
            token.__changed = token.content !== content;
        }
    }
    // Rematch tokens with changed content.
    for (const token of tokens) {
        if (!token.__changed) {
            continue;
        }
        delete token.__changed;
        const pattern = getArgumentPatternByType(token.type);
        assert(pattern);
        pattern.lastIndex = 0;
        const match = pattern.exec(token.content);
        assert(match);
        Object.assign(token, match.groups);
    }
    return tokens;
}
//# sourceMappingURL=PSelectorTokenizer.js.map